{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:46:09.136907Z",
     "start_time": "2023-06-04T13:46:03.865596Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.13.0-rc1'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:46:09.141366Z",
     "start_time": "2023-06-04T13:46:09.138928Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# preprocess training set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('CNN/dataset/training_set',\n",
    "     target_size = (64, 64),\n",
    "     batch_size = 32,\n",
    "     class_mode = 'binary')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:46:09.274981Z",
     "start_time": "2023-06-04T13:46:09.141938Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# preprocess test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('CNN/dataset/test_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:46:09.318939Z",
     "start_time": "2023-06-04T13:46:09.276305Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# build CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:46:09.361513Z",
     "start_time": "2023-06-04T13:46:09.318191Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# convolution\n",
    "64 x 64 image size x 3 full color"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:46:09.366226Z",
     "start_time": "2023-06-04T13:46:09.361732Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# pooling\n",
    "2 x 2 pool size commonly used\n",
    "stride 2 is shift 2 pixels at a time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:46:09.370500Z",
     "start_time": "2023-06-04T13:46:09.367432Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# add second convolutional layer\n",
    "same as above, but dont need input shape because it is already defined"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:46:09.384047Z",
     "start_time": "2023-06-04T13:46:09.371319Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# flattening"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:46:09.390778Z",
     "start_time": "2023-06-04T13:46:09.385596Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# full connection\n",
    "use activation function relu for hidden layer until output layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:46:09.399789Z",
     "start_time": "2023-06-04T13:46:09.390933Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# output layer\n",
    "sigmoid activation function for binary outcome\n",
    "softmax for more than 2 outcomes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:46:09.407676Z",
     "start_time": "2023-06-04T13:46:09.402222Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# compile CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:46:09.416744Z",
     "start_time": "2023-06-04T13:46:09.411248Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train CNN on training set and evaluate on test set\n",
    "from the very first set of training data and test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.6654 - accuracy: 0.5982 - val_loss: 0.5882 - val_accuracy: 0.6950\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.5894 - accuracy: 0.6836 - val_loss: 0.5670 - val_accuracy: 0.7050\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 18s 73ms/step - loss: 0.5463 - accuracy: 0.7204 - val_loss: 0.5177 - val_accuracy: 0.7460\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 18s 72ms/step - loss: 0.5076 - accuracy: 0.7421 - val_loss: 0.4913 - val_accuracy: 0.7665\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 18s 73ms/step - loss: 0.4827 - accuracy: 0.7631 - val_loss: 0.5221 - val_accuracy: 0.7485\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.4775 - accuracy: 0.7695 - val_loss: 0.5038 - val_accuracy: 0.7590\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 18s 72ms/step - loss: 0.4527 - accuracy: 0.7828 - val_loss: 0.4620 - val_accuracy: 0.7885\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 19s 76ms/step - loss: 0.4422 - accuracy: 0.7911 - val_loss: 0.4540 - val_accuracy: 0.7885\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 19s 74ms/step - loss: 0.4217 - accuracy: 0.8045 - val_loss: 0.4577 - val_accuracy: 0.7785\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 19s 77ms/step - loss: 0.4084 - accuracy: 0.8140 - val_loss: 0.4913 - val_accuracy: 0.7775\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x1728f6850>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:49:12.552789Z",
     "start_time": "2023-06-04T13:46:09.417065Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Making a single prediction\n",
    "same size, convert to array, add extra dimension for batch size, dims for dimensions, our \"batch\" is at 0 dimension (first)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('CNN/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image) # convert to 3D array\n",
    "test_image = np.expand_dims(test_image, axis = 0) # add extra dimension for batch size\n",
    "result = cnn.predict(test_image/255.0)\n",
    "training_set.class_indices\n",
    "if result[0][0] > 0.5:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:49:12.624041Z",
     "start_time": "2023-06-04T13:49:12.556079Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "'dog'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:49:12.626927Z",
     "start_time": "2023-06-04T13:49:12.625380Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T13:49:12.628743Z",
     "start_time": "2023-06-04T13:49:12.627409Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
